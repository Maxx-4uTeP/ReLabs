# CPH 07: Проблемы и их решения в Ceph
##### [Оглавление](../README.md)
### Задание:
Заменить сбойный диск.

Вам дан кластер ceph, состоящий из 3 машин, и резервная машина (4 по порядку). На 3 машине был поврежден диск, используемый кластером для хранения. Необходимо настроить резервную машину, добавить ее в кластер и подключить диск.

##### Для решения задачи необходимо сделать следующее:

* Подготовьте резервную машину к вводу в кластер:
* Добавьте ssh от кластера ceph на машину;
* Поменяйте hostname на ceph4, дополните файл /etc/hosts на ceph4 и ceph1, чтобы машины могли обращаться друг к другу по имени хоста.
* Добавьте диск с ceph4 в кластер.
* Удалите сбойный диск:
-Определите его имя (ceph orch ps);
-Удалите запись из crushmap;
-Удалите диск;
-Удалите daemon, отвечающий за сбойный диск.

#### Первоначальная проверка:
* Проверка добавления хоста ceph4 в кластер ceph: FAILED
* Проверка дисков в кластере ceph: FAILED
* Проверка удаления отключенного диска в кластере ceph: OK

```bash
cat /etc/hosts
```
        10.129.0.10 ceph1.local ceph1
        10.129.0.18 ceph2.local ceph2
        10.129.0.32 ceph3.local ceph3

## Практика:
#### Сегодня остановим одну OSD и добавим новую ноду с OSD, потом повторим все то же с mon.
#### Проверяем, что кластер живой. Затем останавливаем OSD на Ceph 3. Добавляем новую ноду Ceph 4.
```bash
ceph orch ps
```
Смотрим на 4 ноде ip адрес и прописываем его в /etc/hosts

        10.129.0.10 ceph1.local ceph1
        10.129.0.18 ceph2.local ceph2
        10.129.0.32 ceph3.local ceph3
        10.129.0.12 ceph4.local ceph4

#### копируем ssh-ключ 
```bash       
ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph4
```
#### На четвертой ноде поставили Ceph-common, обменялись с ней ключиками. Добавляем хост:
```bash
ceph orch host add ceph4 10.129.0.12
```
#### Добавляем с Ceph 4 его диск:
```bash
ceph orch daemon add osd ceph4:/dev/vdb
```
#### Смотрим ceph -s. Идет Recovery.
#### Далее удаляем OSD2 диск, который уже “поломан”:
```bash
ceph osd rm osd.2
```
#### Тот же диск находится в crush map, поэтому надо сначала удалить этот диск из карты crush:
```bash
ceph osd crush remove osd.2
ceph orch daemon rm osd.2 --force
```
#### После удаления демона запускаем ceph -s и видим, что с кластером все хорошо, что прошли все процедуры восстановления.

#### Итоговая проверка:
* Проверка добавления хоста ceph4 в кластер ceph: OK
* Проверка дисков в кластере ceph: OK
* Проверка удаления отключенного диска в кластере ceph: OK


#### Рассмотрим, что бывает с удалением монитора. Выключаем третью ноду, добавляем лейбл mon на четвертую. Добавляем новый монитор, разворачивается демон монитора, видим, что мониторов стало четыре.
```bash
ceph orch host label add ceph4 mon
ceph orch apply mon "ceph1,ceph2,ceph0"
```
#### Удаляем старый монитор:
```bash
ceph mon ok-to-stop mon.ceph3
ceph mon ok-to-rm mon.ceph3
ceph mon rm mon.ceph3
```
#### Удаляем демона и получаем ошибку SSH:
```bash
ceph orch daemon rm mon.ceph3 --force
```
#### Пытаемся удалить хост:
```bash
ceph orch host label rm ceph3 mon
ceph orch host rm ceph3 --offline --force
```
#### Если все проходит нормально, делаем daemon rm, тогда он из внутренних карт удаляет этот демон.
```bash
ceph orch daemon rm mon.ceph3 --force
```
#### Запускаем ceph -s.
#### Перегенерируем конфиг:
```bash
ceph config generate-minimal-conf > ceph.conf
```
#### Он добавил четвертый монитор, и в кворуме стало четыре монитора: первый, второй и четвертый.
#### Можно использовать такой механизм в крайних безвыходных ситуациях.




